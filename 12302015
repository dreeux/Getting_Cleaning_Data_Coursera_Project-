library(caret)


test$Response = 0


## store Id column and remove it from the train and test data


testId = test$Id

train$Id = test$Id = NULL


tmp = rbind(train, test)


cat.var.names <- c(paste("Product_Info_", c(1:3,5:7), sep=""), paste("Employment_Info_", c(2,3,5), sep=""),
                   
		   paste("InsuredInfo_", 1:7, sep=""), paste("Insurance_History_", c(1:4,7:9), sep=""), 
                   
                   "Family_Hist_1", paste("Medical_History_", c(2:14, 16:23, 25:31, 33:41), sep=""))


tmp_factors <- tmp[, cat.var.names]
  

len = length(names(tmp_factors))


for (i in 1:len) {
    
  levels <- unique(tmp_factors[[i]])
  
  tmp_factors[, i] <- as.factor(tmp_factors[, i], levels = levels)

    
  }


tmp <- tmp[, !( names(tmp) %in% names(tmp_factors))]


tmp_new <- cbind(tmp, tmp_factors)


# check row numbers


train <- tmp_new[c(1:59382),]

test <- tmp_new[c(59383:79148),]



## create mlr task and convert factors to dummy features


trainTask = makeRegrTask(data = train, target = "Response")

trainTask = createDummyFeatures(trainTask)

testTask = makeRegrTask(data = test, target = "Response")

testTask = createDummyFeatures(testTask)


## create mlr learner


set.seed(12302015)

lrn = makeLearner("regr.xgboost")

lrn$par.vals = list(

  #nthread             = 30,

  nrounds             = 4000,

  print.every.n       = 20,

  objective           = "reg:linear",

  depth = 21,

  colsample_bytree = 0.66,

  min_child_weight = 3,

  subsample = 0.71

)


# missing values will be imputed by their median


lrn = makeImputeWrapper(lrn, classes = list(numeric = imputeMedian(), integer = imputeMedian()))

## Create Evaluation Function


SQWKfun = function(x = seq(1.5, 7.5, by = 1), pred) {

  preds = pred$data$response

  true = pred$data$truth 

  cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))

  preds = as.numeric(Hmisc::cut2(preds, cuts))

  err = Metrics::ScoreQuadraticWeightedKappa(preds, true, 1, 8)

  return(-err)

}


SQWK = makeMeasure(id = "SQWK", minimize = FALSE, properties = c("regr"), best = 1, worst = 0,

  fun = function(task, model, pred, feats, extra.args) {

    return(-SQWKfun(x = seq(1.5, 7.5, by = 1), pred))

  })



## This is how you could do hyperparameter tuning

# # 1) Define the set of parameters you want to tune (here 'eta')



 ps = makeParamSet(

   makeNumericParam("eta", lower = 0.01, upper = 0.03)

 )


# # 2) Use 3-fold Cross-Validation to measure improvements


 rdesc = makeResampleDesc("CV", iters = 3L)


# # 3) Here we use Random Search (with 10 Iterations) to find the optimal hyperparameter


 ctrl =  makeTuneControlRandom(budget = 10, maxit = 10)


# # 4) now use the learner on the training Task with the 3-fold CV to optimize your set of parameters and evaluate it with SQWK


 res = tuneParams(lrn, task = trainTask, resampling = rdesc, par.set = ps, control = ctrl, measures = SQWK)


 res


# # 5) set the optimal hyperparameter


 lrn = setHyperPars(lrn, par.vals = res$x)


## now try to find the optimal cutpoints that maximises the SQWK measure based on the Cross-Validated predictions


cv = crossval(lrn, trainTask, iter = 4, measures = SQWK, show.info = TRUE)


optCuts = optim(seq(1.5, 7.5, by = 1), SQWKfun, pred = cv$pred)


optCuts



## now train the model on all training data


tr = train(lrn, trainTask)



## predict using the optimal cut-points 


pred = predict(tr, testTask)


preds = as.numeric(Hmisc::cut2(pred$data$response, c(-Inf, optCuts$par, Inf)))


table(preds)


## create submission file


submission = data.frame(Id = testId)


submission$Response = as.integer(preds)


write.csv(submission,   , row.names = FALSE)


######################################################################################################################################

for non linear algos replace a cat. var by number of times

it appears in the set

GBM with out-of-fold treatment of high-cardinality feature 

performs very well
